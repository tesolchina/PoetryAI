# Research Methodology: Enhanced with Risk Management

## Research Design

**Study Type**: Mixed-methods experimental study  
**Setting**: Undergraduate English L2 creative writing course (poetry unit) at HKBU  
**Duration**: 3 months (September - November 2025)

## Participants

- **Target**: 20 English L2 undergraduates
- **Eligibility**: B1+ proficiency on CEFR or institution's placement
- **Distribution**: Equally divided into three groups (6-7 participants each)
- **Awareness condition**: Half aware of parameter settings, half unaware

## Experimental Design

### Conditions
- **Room A (Constrained)**: temperature 0.1-0.2, top p 0.1-0.2
- **Room B (Exploratory)**: temperature 0.8-0.9, top p 0.8-0.9
- **Room C (Control)**: temperature 0.0, top p 0.0 (deterministic responses)

### UI Variants
- **Aware UI**: Shows temperature/top p labels on welcome note
- **Unaware UI**: No mention of parameter settings

## Risk Management Framework

### Risk 1: Setup and Data Collection Station Management

**Risk**: Establishing credible data collection across multiple classes may randomize findings and reduce convincing evidence.

**Mitigation Strategies**:
- **Single Class Cohort**: Recruit all participants from one specific English L2 poetry class to ensure homogeneous baseline conditions
- **Structured Scheduling**: Implement fixed 50-minute sessions twice weekly in dedicated computer lab
- **Incentive Structure**: 
  - Extra credit points (5% of course grade) for completion
  - Voluntary participation with alternative assignments for non-participants
  - Clear participation criteria communicated via course syllabus

**Implementation Protocol**:
- Reserve computer lab for consistent 6-week period
- Assign fixed workstations to maintain technical consistency
- Maintain detailed attendance logs and technical issue documentation

### Risk 2: Project Design Sequence Validation

**Risk**: Proposed sequence may not meet credible standards due to lack of expertise benchmarking.

**Mitigation Strategies**:
- **Literature Validation**: Align methodology with established ChatGPT educational research frameworks (Zhang et al., 2023; Wang & Liu, 2024)
- **Expert Review**: Submit methodology for review by experienced CALL researchers
- **Pilot Testing**: Conduct 2-week pilot with 5 volunteers to validate sequence effectiveness

**Enhanced Sequence Protocol**:
1. **Pre-briefing Session** (Week 1): Parameter awareness training + poetry baseline assessment
2. **Interaction Phase** (Weeks 2-5): Structured chatbot sessions with weekly reflection journals
3. **Post-experiment Data Collection** (Week 6): Individual surveys followed by focus group discussions
4. **Validation Phase**: Member-checking sessions with participants to verify interpretation accuracy

### Risk 3: Student Sample Selection and Clarity

**Risk**: Unclear selection criteria and potential for subjective, unverifiable survey responses.

**Mitigation Strategies**:

**Purposive Sampling Criteria**:
- English proficiency: IELTS 6.0+ or institutional equivalent
- Poetry writing experience: Minimal to moderate (to ensure learning potential)
- Technology comfort: Basic computer literacy confirmed via pre-screening
- Availability: Commitment to full 6-week participation

**Participant Communication Protocol**:
- **Selection Transparency**: Written explanation of criteria provided to all potential participants
- **Purpose Clarity**: Detailed information sheet explaining research goals and individual contribution importance
- **Data Verification Measures**:
  - Triangulated survey responses with chat log analysis
  - Follow-up interviews for clarification of ambiguous responses
  - Peer verification through focus group consensus-building

### Risk 4: Control Group Implementation

**Risk**: Without proper control group, data-backed comparisons across user groups become impossible.

**Mitigation Strategies**:

**Three-Tier Control Design**:
- **Group A (Low Creativity)**: temperature 0.1, top p 0.1
- **Group B (High Creativity)**: temperature 0.9, top p 0.9  
- **Group C (Deterministic Control)**: temperature 0.0, top p 0.0

**Control Group Protocol**:
- Maintain identical interaction protocols across all groups
- Use same prompts and session structures
- Implement blind analysis where coders don't know group assignments
- Statistical analysis plan for between-group comparisons using ANOVA and post-hoc tests

### Risk 5: Prompt Design and Data Integrity

**Risk**: Inadequately tailored prompts leading to poor data quality ("garbage in, garbage out").

**Mitigation Strategies**:

**Prompt Validation Process**:
1. **Expert Review**: Submit prompts to 3 poetry education specialists for feedback
2. **Cognitive Load Testing**: Ensure prompts don't overwhelm L2 learners
3. **Pilot Refinement**: Test with 5 students and refine based on confusion points
4. **Standardization**: Create prompt library with consistent format and complexity

**Quality Assurance Measures**:
- **Prompt Consistency**: All facilitators use identical scripts
- **Response Quality Metrics**: Establish minimum word counts and engagement indicators
- **Real-time Monitoring**: Research assistant monitors sessions for prompt adherence
- **Backup Protocols**: Alternative prompts prepared for technical failures

## Data Collection Methods

1. **Chat logs**: Complete interaction transcripts with timestamp analysis
2. **Audio recordings**: Panel discussions and debates (with consent protocols)
3. **Artifacts**: Poem versions and revisions with version control tracking
4. **Surveys**: Pre/post questionnaires on self-efficacy and perceptions (validated instruments)
5. **API logging**: Granular interaction data with parameter verification
6. **Reflection journals**: Weekly participant reflections on experience

## Analysis Framework

### Interaction Types (Pre-defined)
- **Type A**: Diagnosis → Repair (form/constraint fixes)
- **Type B**: Exemplar Pivot (anchor → apply characteristics)  
- **Type C**: Surprise Harvest (divergent → selective uptake)

### Coding Scheme
- Frequency analysis of interaction types with inter-rater reliability (Cohen's κ > 0.8)
- Sequencing patterns (e.g., C→A sequences) with Markov chain analysis
- Impact on revision and metalinguistic talk using pre-post comparison
- Parameter awareness effects using mixed-effects modeling

## Validity and Reliability

### Technical Validity
- **Parameter fidelity**: Real-time logging and audit of actual settings used
- **Model stability**: Fix GPT model version and API parameters for study duration
- **System reliability**: Backup servers and connection redundancy

### Research Validity
- **Inter-rater reliability**: Multiple independent coders for interaction types (target κ > 0.8)
- **Triangulation**: Multiple data sources (logs, audio, artifacts, surveys, journals)
- **Member checking**: Participant validation of interpretations
- **External validity**: Compare findings with similar L2 writing studies

### Ethical Considerations
- **Informed consent**: Detailed consent process with withdrawal options
- **Data protection**: Anonymization protocols and secure storage
- **Participant welfare**: Regular check-ins and support availability

## Contingency Planning

### Technical Contingencies
- **System failure**: Backup recording methods and alternative platforms
- **Connectivity issues**: Offline alternatives and make-up sessions
- **Model changes**: Version locking and emergency migration protocols

### Research Contingencies
- **Low participation**: Recruitment backup plan and minimum viable sample strategies
- **Data quality issues**: Additional validation measures and exclusion criteria
- **Timeline delays**: Flexible scheduling and priority milestone identification

---
**Status**: Enhanced methodology with risk management framework  
**Next Steps**: Ethics approval submission, pilot study implementation, expert methodology review  
**Risk Assessment**: Comprehensive mitigation strategies implemented for all identified risk factors