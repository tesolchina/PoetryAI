# Literature Review

This chapter reviews existing research across three key domains: L2 creative writing pedagogy, human-AI collaborative creativity, and LLM parameter effects on generation quality. The review is organized to establish theoretical foundations for the three interaction types framework (Diagnosis → Repair, Exemplar Pivot, Surprise Harvest) and identify gaps that this study addresses.

## 2.1 L2 Creative Writing and Poetry Pedagogy

### 2.1.1 Foundations of L2 Poetry Writing

Poetry writing in second language contexts presents unique pedagogical opportunities and challenges that distinguish it from other forms of L2 writing instruction. Hanauer (2010) established poetry as a legitimate research methodology and pedagogical tool, arguing that poetic expression allows L2 learners to explore language creatively while developing both linguistic competence and personal voice. His longitudinal study of L2 poetry writing revealed that students develop metalinguistic awareness through poetic composition, particularly when engaging with form, rhythm, and imagery constraints.

This foundational work demonstrates that L2 poetry writing serves dual functions: **language development** through structured practice with vocabulary, syntax, and phonological patterns, and **identity formation** through personal expression and cultural reflection. Hanauer's findings indicate that L2 learners show significant improvement in linguistic risk-taking and creative confidence when poetry writing is scaffolded appropriately, establishing the pedagogical rationale for our **Type B: Exemplar Pivot** interaction type.

Fithriani (2021) extended this work by examining Indonesian EFL students' strategies in poetry composition, identifying three key approaches: **imitation-based learning** (modeling existing poems), **emotion-driven expression** (personal experience as content source), and **collaborative construction** (peer and teacher interaction). Her analysis reveals that students benefit most from structured progression through these approaches, with imitation serving as a crucial scaffolding mechanism before independent creative expression.

The scaffolding dimension is further developed by Kerbs, McQueston, and Lawrance (2024), whose recent study on "Playing with Words" demonstrates how systematic poetry instruction supports overall writing development. Their framework emphasizes **constraint-based creativity**—using formal poetry structures (meter, rhyme, specific forms) to support rather than limit creative expression. This approach aligns closely with our research interest in how AI parameter constraints might similarly support L2 creative development.

### 2.1.2 Technology Integration in L2 Creative Writing

The integration of technology into L2 creative writing instruction has evolved significantly with the advent of AI tools. Li (2025) provides comprehensive analysis of generative AI applications in L2 writing contexts, identifying both opportunities and challenges. His framework distinguishes between **generative support** (AI as content creator), **collaborative support** (AI as writing partner), and **evaluative support** (AI as assessment tool), noting that collaborative applications show greatest promise for creative writing instruction.

Li's research particularly emphasizes the importance of maintaining student agency in AI-assisted writing, arguing that tools should enhance rather than replace human creative decision-making. This perspective aligns with Crosthwaite and Baisa's (2023) analysis of generative AI's impact on data-driven learning approaches. They argue that AI tools can complement corpus-based language learning by providing contextualized examples and scaffolded practice opportunities, but require careful pedagogical integration to avoid passive consumption of AI-generated content.

## 2.2 Human-AI Creative Collaboration

### 2.2.1 Collaborative Writing Frameworks

The emergence of AI as a creative collaborator has generated substantial research into human-AI creative partnerships. Clark et al. (2018) conducted foundational studies on creative writing with machine-in-the-loop systems, examining how writers interact with AI in story and slogan generation tasks. Their analysis identified three primary collaboration patterns: **AI as idea generator** (human selects and develops AI suggestions), **AI as writing assistant** (human directs, AI executes), and **AI as creative partner** (iterative co-creation with shared agency).

This framework is significantly expanded by Coenen et al. (2022) in their analysis of Wordcraft, an LLM-based story writing tool. Their extensive user studies with professional writers revealed that successful human-AI creative collaboration depends on **serendipitous discovery**—moments when AI generates unexpected content that inspires new creative directions. This finding directly informs our **Type C: Surprise Harvest** interaction type, where AI's capacity for novel combinations creates pedagogical opportunities.

Coenen et al.'s work is particularly relevant for understanding how AI parameter settings affect collaborative dynamics. They observed that higher temperature settings (0.7-0.9) generated more surprising and creatively stimulating content, while lower settings (0.1-0.3) provided more predictable and controllable outputs. However, their focus on experienced writers leaves gaps regarding how L2 learners, who lack extensive linguistic resources, might experience these different AI behaviors.

### 2.2.2 Collaborative Process Analysis

Qian et al. (2023) provide detailed process analysis of human-AI co-creativity in prewriting activities, coining the metaphor of AI as "having a second mind." Their study with university students revealed that AI collaboration affects cognitive load distribution, with AI handling ideational generation while humans focus on evaluation and integration. This cognitive partnership model suggests pedagogical implications for L2 contexts, where students might benefit from AI support for vocabulary and conceptual generation while maintaining control over creative decisions.

Ashktorab et al. (2020) examined human-AI collaboration in cooperative game settings, focusing on social perception and trust development. Their findings indicate that successful collaboration depends on **transparency of AI capabilities**, **predictability of AI behavior**, and **clear division of creative labor**. These factors directly inform our research design's parameter awareness conditions, as understanding AI behavior may significantly affect collaboration quality.

Michel et al. (2025) provide more direct relevance to L2 contexts through their analysis of collaborative writing with generative AI models in German L2 classrooms. Their study of revision and deliberation processes revealed that AI assistance significantly improves drafting efficiency but requires explicit instruction in critical evaluation of AI suggestions. Students who received training in AI literacy showed better integration of AI suggestions and more sophisticated revision strategies.

### 2.2.3 Creative Partnership Dynamics

Recent research by Nguyen et al. (2024) on human-AI collaboration patterns in academic writing identifies four collaboration modes: **directive** (human commands, AI executes), **consultative** (human seeks specific AI input), **collaborative** (shared creative control), and **autonomous** (AI generates, human selects). Their analysis of 200+ writing sessions reveals that collaborative mode produces highest satisfaction and quality outcomes, but requires substantial user expertise to manage effectively.

This finding suggests important implications for L2 contexts, where students may lack the linguistic confidence to engage in truly collaborative relationships with AI tools. The progression from directive through consultative to collaborative modes may represent a developmental pathway that pedagogy should explicitly support.

## 2.3 LLM Parameters and Generation Control

### 2.3.1 Temperature Effects on Creativity

The technical literature on LLM parameters provides crucial background for understanding how AI configuration affects creative collaboration. Peeperkorn et al. (2024) directly address the question "Is temperature the creativity parameter of large language models?" through systematic analysis of output characteristics across temperature ranges. Their findings indicate that temperature affects **lexical diversity**, **semantic coherence**, and **creative surprise**, but its relationship to human-perceived creativity is complex and task-dependent.

Peeperkorn et al.'s analysis reveals that low temperature (0.1-0.3) produces **highly coherent but predictable outputs**, medium temperature (0.4-0.7) balances **coherence with novelty**, and high temperature (0.8-1.0) generates **surprising but potentially incoherent content**. For educational applications, they recommend dynamic temperature adjustment based on learning objectives, with lower settings for skill building and higher settings for creative exploration.

Li et al. (2025) extend this analysis specifically to L2 writing contexts, examining temperature effects on vocabulary complexity, grammatical accuracy, and creative expression in AI-assisted writing tasks. Their study with Chinese L2 English writers revealed that intermediate temperature settings (0.5-0.6) optimize the balance between linguistic accessibility and creative stimulation for L2 learners.

### 2.3.2 Top-p Nucleus Sampling Effects

Ravfogel, Goldberg, and Goldberger (2023) provide technical analysis of nucleus sampling (top-p) effects on text generation quality. Their "conformal nucleus sampling" approach demonstrates that top-p parameter affects **vocabulary breadth**, **semantic consistency**, and **stylistic variation**. Low top-p values (0.1-0.3) restrict vocabulary to high-probability words, creating **conservative, accessible outputs**, while high top-p values (0.8-1.0) allow **diverse vocabulary usage** but may introduce **semantic inconsistencies**.

For educational applications, Ravfogel et al. suggest that top-p adjustment can serve as a **difficulty control mechanism**, with lower values providing linguistic scaffolding for beginners and higher values offering vocabulary expansion opportunities for advanced learners. This finding directly supports our research hypothesis that parameter awareness might enhance pedagogical effectiveness.

Üzümcü and Ganiz (2025) provide cross-linguistic validation of parameter effects through analysis of Turkish LLM performance across temperature and top-p settings. Their findings suggest that optimal parameter ranges are **language-specific**, with morphologically complex languages requiring different configurations than English. This research implies that parameter recommendations may need cultural and linguistic customization.

### 2.3.3 Parameter Interactions and User Experience

Holtzman et al. (2019) established foundational understanding of neural text degeneration, demonstrating how different sampling strategies affect output quality and human preference. Their analysis of nucleus sampling versus other approaches revealed that top-p sampling produces more **human-like text** than top-k or pure temperature sampling, establishing nucleus sampling as the preferred method for interactive applications.

The user experience dimension is explored by Ippolito et al. (2022) in their study of professional writers using AI-powered writing assistants. Their findings indicate that parameter transparency affects user trust and creative satisfaction, with writers preferring systems that provide **clear control over AI behavior**. However, their focus on expert users leaves questions about optimal parameter presentation for novice L2 writers.

Park (2023) addresses parameter effects from an editorial perspective, examining how different AI configurations affect writing quality and author satisfaction. His analysis suggests that **parameter education** significantly improves user outcomes, as writers who understand parameter effects make more strategic configuration choices.

## 2.4 Feedback and Interaction Analysis in L2 Contexts

### 2.4.1 Corrective Feedback Theory

The theoretical foundation for our **Type A: Diagnosis → Repair** interaction type derives from Lyster and Ranta's (1997) seminal work on corrective feedback and learner uptake in communicative classrooms. Their taxonomy of feedback types—**explicit correction**, **recasts**, **clarification requests**, **metalinguistic feedback**, **elicitation**, and **repetition**—provides a framework for analyzing how AI might function as a feedback provider in creative writing contexts.

Lyster and Ranta's analysis of uptake patterns revealed that different feedback types produce varying rates of **immediate repair**, **needs repair**, and **no uptake**. Explicit correction and metalinguistic feedback showed highest uptake rates, while recasts, despite being most frequent, showed lower immediate uptake but potential delayed benefits. This finding suggests that AI systems configured for explicit diagnostic feedback might be more effective for immediate learning, while more subtle AI suggestions might support long-term development.

Wang and Wang (2025) extend corrective feedback analysis to AI-assisted writing contexts through their APSE (Analyze, Plan, Synthesize, Evaluate) model for critical AI literacy. Their framework emphasizes that effective AI feedback requires **explicit instruction in feedback interpretation** and **strategic response planning**. L2 writers who received APSE training showed significantly better integration of AI feedback compared to control groups.

### 2.4.2 Process-Based Assessment

McGregor, Purver, and Wiggins (2016) provide methodological foundations for process-based evaluation of computer-generated poetry, establishing frameworks that apply to human-AI collaborative composition. Their approach emphasizes **revision tracking**, **decision point analysis**, and **creative process documentation** rather than solely evaluating final products.

Wang (2024) applies process analysis specifically to AI-assisted writing by native and non-native English speakers, revealing significant differences in how L2 writers engage with AI suggestions. L2 writers showed greater reliance on AI for **vocabulary selection** and **grammatical confirmation**, while native speakers used AI primarily for **ideational development** and **stylistic experimentation**. These findings suggest that parameter configurations optimized for L2 learners might differ substantially from those designed for native speakers.

## 2.5 Creativity Assessment and Measurement

### 2.5.1 Computational Creativity Frameworks

Franceschelli and Musolesi (2025) provide comprehensive analysis of creativity assessment in large language models, establishing metrics that apply to human-AI collaborative creativity. Their framework distinguishes between **novelty** (statistical unusualness), **value** (quality and appropriateness), and **intentionality** (purposeful creative choices). For educational applications, they emphasize that creativity assessment must consider both **process** (how creative decisions emerge) and **product** (final creative outputs).

Zhao et al. (2025) extend creativity assessment to specific tasks, developing metrics for poetic creativity that include **semantic coherence**, **formal innovation**, **emotional resonance**, and **cultural appropriateness**. Their findings indicate that human-AI collaborative poetry often achieves higher scores on formal and semantic dimensions than human-only composition, but may score lower on emotional resonance and cultural appropriateness without explicit guidance.

Orwig et al. (2024) examine "the language of creativity" through comparative analysis of human and LLM creative outputs. Their linguistic analysis reveals that AI-generated creative text shows distinct patterns in **metaphor usage**, **syntactic complexity**, and **semantic density** that distinguish it from human creative writing. For pedagogical applications, they suggest that these differences might serve as **learning opportunities** rather than limitations, helping students develop analytical skills about creative language use.

## 2.6 Research Gaps and Study Positioning

### 2.6.1 Identified Gaps

Despite substantial research in human-AI creative collaboration, significant gaps remain in understanding how parameter configurations affect L2 creative writing pedagogy. Existing studies focus primarily on **native speakers** (Coenen et al., 2022; Ippolito et al., 2022) or **general writing tasks** (Michel et al., 2025; Wang, 2024) rather than specifically examining **poetry composition** in **L2 educational contexts** with **systematic parameter manipulation**.

The **parameter awareness dimension** represents another significant gap. While research establishes that parameter settings affect output characteristics (Peeperkorn et al., 2024; Li et al., 2025), limited investigation exists into whether **user awareness of parameter settings** affects collaborative behavior and learning outcomes. This gap is particularly relevant for educational contexts, where parameter transparency might serve pedagogical functions beyond technical control.

The **interaction type framework** developed in this study addresses gaps in understanding how different AI behaviors support different learning objectives. While Lyster and Ranta's (1997) corrective feedback taxonomy provides foundation for diagnostic interactions, and Hanauer's (2010) imitation-transformation approach supports exemplar-based learning, limited research examines how **AI parameter configurations** can be strategically employed to facilitate these different interaction types.

### 2.6.2 Study Contributions

This research addresses identified gaps through several key contributions:

1. **Systematic parameter manipulation in L2 creative writing contexts**, examining how temperature and top-p settings affect collaborative poetry composition with specific attention to L2 learner needs and capabilities.

2. **Parameter awareness investigation**, determining whether transparency about AI configuration enhances or hinders creative collaboration and learning outcomes in educational settings.

3. **Three interaction types framework**, providing theoretical structure for understanding how different AI behaviors (Diagnosis → Repair, Exemplar Pivot, Surprise Harvest) support different pedagogical objectives in L2 creative writing instruction.

4. **Mixed-methods empirical validation**, combining interaction analysis, linguistic analysis, and participant feedback to provide comprehensive understanding of human-AI creative collaboration in L2 educational contexts.

These contributions advance both **theoretical understanding** of human-AI creative collaboration and **practical knowledge** for implementing AI tools in L2 creative writing pedagogy, addressing calls for more systematic research into educational applications of generative AI (Li, 2025; Michel et al., 2025).

## 2.7 Theoretical Framework Integration

The literature review establishes three theoretical pillars that support this study's conceptual framework:

**L2 Creative Writing Pedagogy** (Hanauer, 2010; Fithriani, 2021; Kerbs et al., 2024) demonstrates that poetry writing serves both linguistic development and creative expression functions in L2 contexts, with scaffolding and constraint-based approaches showing particular effectiveness.

**Human-AI Creative Collaboration** (Coenen et al., 2022; Qian et al., 2023; Clark et al., 2018) reveals that successful creative partnerships depend on strategic role distribution, serendipitous discovery opportunities, and appropriate transparency about AI capabilities.

**LLM Parameter Effects** (Peeperkorn et al., 2024; Li et al., 2025; Ravfogel et al., 2023) establish that temperature and top-p settings significantly affect output creativity, coherence, and linguistic accessibility, with optimal configurations being task- and user-specific.

Integration of these three domains through the lens of **interaction analysis** (Lyster & Ranta, 1997; McGregor et al., 2016) provides the theoretical foundation for investigating how parameter configurations can be strategically employed to support different types of pedagogically valuable interactions in L2 creative writing contexts.
